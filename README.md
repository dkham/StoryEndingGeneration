# Story Ending Generation

![An-example-of-the-input-story-context-and-output-story-endings-for-this-task-All-of-the](https://github.com/dkham/dkham/assets/72950291/b4b0703e-e342-4ea0-b02d-2118caa3eb84)

Generating compelling story endings is a challenging task in natural language processing (NLP) due to the complexity of language, context, and narrative structure. In this project, we aim to develop a sentence generation model for story ending using deep learning techniques and the ROCStories corpus. 
 
In our analysis, we compare four state-of-the-art NLP models, Bidirectional LSTM (Bi-LSTM), BERT, T5, and OPT, to generate the fifth sentence given the first four sentences of a story from the corpora.
 
Our approach involves training the models on the ROC stories corpus to learn patterns and relationships between sentences, and then using the trained models to generate new, coherent sentences that fit seamlessly into the story's narrative arc. To evaluate the performance of our models, we will use BLEURT, ROUGE, and Human Evaluation to assess each modelâ€™s performance. 

**Project owners:** Daisy Khamphakdy, Melissa Hartwick, Tanmay Mahapatra

*UC Berkeley, Master of Information and Data Science / W266 / Natural Language Processing and Deep Learning*
